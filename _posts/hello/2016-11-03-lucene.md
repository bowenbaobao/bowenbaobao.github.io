---
layout: post
title: lucene 笔记
permalink: /:categories/lucene_url/
date: 2016-11-01 09:30:15 +0800
category: Java Search
tags: [lucene]
---



### Lucene 4.10.4

####  POM配置
```
<!-- org.apache.lucene 4.10.4 -->
		<dependency>
			<groupId>org.apache.lucene</groupId>
			<artifactId>lucene-core</artifactId>
			<version>4.10.4</version>
		</dependency>
		<dependency>
			<groupId>org.apache.lucene</groupId>
			<artifactId>lucene-analyzers-common</artifactId>
			<version>4.10.4</version>
		</dependency>
		<dependency>
			<groupId>org.apache.lucene</groupId>
			<artifactId>lucene-queryparser</artifactId>
			<version>4.10.4</version>
		</dependency>
		<dependency>
			<groupId>org.apache.lucene</groupId>
			<artifactId>lucene-highlighter</artifactId>
			<version>4.10.4</version>
		</dependency>
		<dependency>
			<groupId>org.apache.lucene</groupId>
			<artifactId>lucene-sandbox</artifactId>
			<version>4.10.4</version>
		</dependency>
		<dependency>
			<groupId>org.apache.lucene</groupId>
			<artifactId>lucene-queries</artifactId>
			<version>4.10.4</version>
		</dependency>
		<dependency>
			<groupId>org.apache.lucene</groupId>
			<artifactId>lucene-memory</artifactId>
			<version>4.10.4</version>
		</dependency>
		<dependency>
			<groupId>org.apache.lucene</groupId>
			<artifactId>lucene-codecs</artifactId>
			<version>4.10.4</version>
		</dependency>
		<dependency>
			<groupId>org.apache.lucene</groupId>
			<artifactId>lucene-analyzers-icu</artifactId>
			<version>4.10.4</version>
		</dependency>
```

####  IK包
```
		<dependency>
			<groupId>org.wltea</groupId>
			<artifactId>IKAnalyzer</artifactId>
			<version>IKAnalyzer2012FF_u1</version>
		</dependency>
```
IK包名:IKAnalyzer-IKAnalyzer2012FF_u1.jar


#### java 代码块

#####  SearchConstant 

全局配置类

```
import java.io.FileInputStream;
import java.io.IOException;
import java.io.InputStream;
import java.util.Properties;
import org.apache.lucene.document.DoubleField;
import org.apache.lucene.document.FieldType;
import org.apache.lucene.document.FloatField;
import org.apache.lucene.document.IntField;
import org.apache.lucene.document.LongField;
import org.apache.lucene.index.FieldInfo.IndexOptions;
import org.apache.lucene.util.Version;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * @describe 系统常量类
 * @author bowen_bao
 * @date 2015年9月8日
 */
public class SearchConstant {
	
	 private static Logger logger = LoggerFactory.getLogger(SearchConstant.class);
		  
	 //搜索index path
	 public final static String ECNEW_INDEX_PATH="/opt/searchIndex/ecnew";        //服务器搜索索引库地址
	 
	 //搜索lucene版本
	 public final static Version SYS_LUCENE_VERSION=Version.LUCENE_4_10_4;
	 
	 //搜索高亮标签
	 public final static String HIGHLIGHT_BEGIN="<font color='#ec6a00'>"; 
	 public final static String HIGHLIGHT_END="</font>";
	
	 //定义索引的数据格式
	public static final FieldType STORE_YES_ANALYZED=new FieldType();//存储、分词
	public static final FieldType STORE_YES_ANALYZED_NO=new FieldType();//存储，不分词
	public static final FieldType STORE_YES_INDEX_NO=new FieldType();//存储，不索引
	public static final FieldType STORE_NO_ANALYZED=new FieldType();//不存储，分词
	public static final FieldType STORE_NO_ANALYZED_NO=new FieldType();//不存储，不分词
	
	public static final FieldType STORE_YES_INT=IntField.TYPE_STORED;//Int 存储
	public static final FieldType STORE_YES_LONG=LongField.TYPE_STORED;//Long 存储
	public static final FieldType STORE_YES_FLOAT=FloatField.TYPE_STORED;//Float 存储
	public static final FieldType STORE_YES_DOUBLE=DoubleField.TYPE_STORED;//Double存储
		
		
		static{
			STORE_YES_ANALYZED.setStored(true);
			STORE_YES_ANALYZED.setIndexed(true);
			STORE_YES_ANALYZED.setTokenized(true);//分词
			STORE_YES_ANALYZED.setOmitNorms(false);//是否忽略加权基准值     true:忽略    false:不忽略      加权基准值:长度标准化因子、字段权重
			/**
			    IndexOptions  修改倒排索引属性
				IndexOptions.DOCS_ONLY  documemts被索引，词频和位置被忽略
				IndexOptions.DOCS_AND_FREQS   documents、词频被索引，term位置被忽略    对field短语或有关位置的查询会抛异常
				IndexOptions.DOCS_AND_FREQS_AND_POSITIONS  全文索引的默认设置：打分、位置检索都支持
				IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS  索引字符相对位置的偏移量
			 */
			STORE_YES_ANALYZED.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);
			STORE_YES_ANALYZED.freeze(); //阻止field属性未来可能的变更
			
			
			STORE_YES_ANALYZED_NO.setStored(true);
			STORE_YES_ANALYZED_NO.setIndexed(true);
			STORE_YES_ANALYZED_NO.setTokenized(false);
			STORE_YES_ANALYZED_NO.setOmitNorms(false);
			STORE_YES_ANALYZED_NO.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);
			STORE_YES_ANALYZED_NO.freeze();
			
			
			STORE_YES_INDEX_NO.setStored(true);
			STORE_YES_INDEX_NO.setIndexed(false);
			STORE_YES_INDEX_NO.setTokenized(false);
			STORE_YES_INDEX_NO.setOmitNorms(true);
			STORE_YES_INDEX_NO.setIndexOptions(null);//只存储，不索引，无倒排索引属性
			STORE_YES_INDEX_NO.freeze();
			
			
			STORE_NO_ANALYZED.setStored(false);
			STORE_NO_ANALYZED.setIndexed(true);
			STORE_NO_ANALYZED.setTokenized(true);
			STORE_NO_ANALYZED.setOmitNorms(false);
			STORE_NO_ANALYZED.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);
			STORE_NO_ANALYZED.freeze();
			
			STORE_NO_ANALYZED_NO.setStored(false);
			STORE_NO_ANALYZED_NO.setIndexed(true);
			STORE_NO_ANALYZED_NO.setTokenized(false);
			STORE_NO_ANALYZED_NO.setOmitNorms(false);
			STORE_NO_ANALYZED_NO.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS);
			STORE_NO_ANALYZED_NO.freeze();
			
		}
		
		
		//indexReader刷新器时间
		public static final long INDEXREADER_SLEEP_TIME=1*1000L;
			    
		 
		
}

```


#####   SearchUtil

核心类：  Analyzer 、 IndexWriter 、 IndexSearch 、 Similarity 的定义

```

import java.io.File;
import java.text.ParseException;
import java.text.SimpleDateFormat;
import java.util.ArrayList;
import java.util.Date;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.miscellaneous.PerFieldAnalyzerWrapper;
import org.apache.lucene.index.DirectoryReader;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.IndexWriter;
import org.apache.lucene.index.IndexWriterConfig;
import org.apache.lucene.index.IndexWriterConfig.OpenMode;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.similarities.Similarity;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.FSDirectory;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.stereotype.Component;
import org.wltea.analyzer.lucene.IKAnalyzer;
import com.sekorm.searchengine.common.constant.SearchConstant;

@Component("searchUtil")
public class SearchUtil {
	
	private final Logger log = LoggerFactory.getLogger(this.getClass());
	
	private  IndexWriter indexWriter=null;
	private  IndexSearcher  indexSearcher=null;
	private  Analyzer analyzer=null;               //默认分词器
	private  Analyzer commaAnalyzer=null;          //自定义分词器
	private  String indexPath=SearchConstant.ECNEW_INDEX_PATH;  //索引path
	private  Similarity ecnewSimilarity=null;     //自定义相似器
	
	
	SearchUtil(){
		init();
	}
	
	/**
	 * 
	 * @describe 初始化相关数据
	 *
	 * @author bowen_bao
	 * @date 2015年7月20日
	 * @param
	 * @return
	 */
	public void init(){
		new Thread(){
			public void run(){
				initData();
			}
		}.start();
	}
	
	public synchronized void initData(){
		try {
			log.info("===SearchUtil initDate start===");
			
			//索引目录
			Directory indexDir=FSDirectory.open(new File(indexPath));
			
			Analyzer  defaultAnalyzer=new IKAnalyzer();
			Analyzer  patternAnalyzer=new PatternAnalyzer(",");
			Map<String,Analyzer> fieldAnalyzers=new HashMap<String,Analyzer>();
			//需要逗号分词的
			fieldAnalyzers.put("keyword", patternAnalyzer);
			fieldAnalyzers.put("searchKeyword", patternAnalyzer);
			fieldAnalyzers.put("brandName", patternAnalyzer);
			fieldAnalyzers.put("brandKeyword", patternAnalyzer);
			fieldAnalyzers.put("goodsName", patternAnalyzer);
			fieldAnalyzers.put("elecName", patternAnalyzer);
			fieldAnalyzers.put("sname",patternAnalyzer);
			fieldAnalyzers.put("skeyword", patternAnalyzer);
			fieldAnalyzers.put("plName",patternAnalyzer);
			fieldAnalyzers.put("plKeyword", patternAnalyzer);
			fieldAnalyzers.put("pnName",patternAnalyzer);
			fieldAnalyzers.put("pnKeyword", patternAnalyzer);
			fieldAnalyzers.put("pnResemblecode",patternAnalyzer);
			fieldAnalyzers.put("pnPackages",patternAnalyzer);
			fieldAnalyzers.put("pnPacking",patternAnalyzer);
			fieldAnalyzers.put("searchKeywordindex",patternAnalyzer);
			
			
			//PerFieldAnalyzerWrapper 可以使得不同的field使用不同的analyzer进行搜索,相当于Analyzer的组
			PerFieldAnalyzerWrapper ecanalyzer=new PerFieldAnalyzerWrapper(defaultAnalyzer,fieldAnalyzers);
			
			//创建indexWriter  索引写者
			IndexWriterConfig iwc=new IndexWriterConfig(SearchConstant.SYS_LUCENE_VERSION,ecanalyzer);
			iwc.setOpenMode(OpenMode.CREATE_OR_APPEND);
			//设置自己的相似器
			iwc.setSimilarity(getEcnewSimilarity());			
			indexWriter=new IndexWriter(indexDir, iwc);
			
			//创建indexSearcher  索引读者
			IndexReader indexReader=DirectoryReader.open(indexWriter,true);			
			indexSearcher=new IndexSearcher(indexReader);

			//设置自己的相似器
			indexSearcher.setSimilarity(getEcnewSimilarity());
			
			analyzer=new IKAnalyzer();
			
			log.info("===SearchUtil initDate end===");
			
		} catch (Exception e) {
			log.info("===SearchUtil initDate error===",e);
		}
	}
	
	public IndexWriter getIndexWriter(){
		if(indexWriter!=null){
			return indexWriter;
		}else{
			initData();
			return indexWriter;
		}
	}
	
	
	public IndexSearcher getIndexSearcher(){
		if(indexSearcher!=null){
			return indexSearcher;
		}else{
			initData();
			return indexSearcher;
		}
	}
	
	public Analyzer getAnalyzer(){
		if(analyzer!=null){
			return analyzer;
		}else{
			return new IKAnalyzer();
		}
	}
	
	/**
	 * 自定义{ 英文,}分词器
	 * @return   Analyzer
	 */
	public Analyzer getcommaAnalyzer(){
		if(commaAnalyzer!=null){
			return commaAnalyzer;
		}else{
			return new PatternAnalyzer(",");
		}
	} 
	
	/**
	 * Lucene 对时间段的查询比较弱，把时间转成long ,对long 进行范围search
	 * @describe  时间  ：  String yyyy-MM-dd hh:mm:ss 转Long	
	 * @author bowen_bao
	 * @date 2015年7月20日
	 * @param
	 * @return
	 */
	public Long DateStringToLong(String date){
		try {
			Date d=new SimpleDateFormat("yyyy-MM-dd hh:mm:ss").parse(date);
			return d.getTime();
		} catch (ParseException e) {
			log.error("SearchUtil  DateStringToLong error" + e.getMessage());
			e.printStackTrace();
		}
		return 0l;
	}
	
	
	//在indexWriter 更新索引后，索引commit，更新indexSearch
	public synchronized  void refreshSearch(){
		try {
			IndexReader oldReader=indexSearcher.getIndexReader();
			indexWriter.commit();
			IndexReader newReader=DirectoryReader.openIfChanged((DirectoryReader) oldReader,indexWriter,true);
			if(null!=newReader && newReader!=oldReader){
				indexSearcher=new IndexSearcher(newReader);
				indexSearcher.setSimilarity(getEcnewSimilarity());//更新indexSearch时，需要设置相似器
				Thread.sleep(SearchConstant.INDEXREADER_SLEEP_TIME);
				oldReader.close();
			}
		} catch (Exception e) {
			log.error("SearchUtil refreshSearch error ",e);
		}
	}
	
	public Similarity   getEcnewSimilarity(){
		if(ecnewSimilarity==null){
			ecnewSimilarity=new EcNewSimilarity();
			return ecnewSimilarity;
		}else{
			return ecnewSimilarity;
		}
	}
	
	
	//***************************************************非搜索Util
	
	/**
	 * list 集合转String  ,以 逗号连接
	 */
	public String  ListToString(List<String> list){
		String str="";
		for(String s:list){
			str+=s+",";
		}
		if(!"".equals(str)  &&  str.length()>0){
			str=str.substring(0, str.length()-1);
		}
		return str;
	}
	
	/**
	 * String  ,以 逗号连接 转 list 集合
	 */
	public List<String>  StringToList(String keyword){
		List<String> list=new ArrayList<String>();
		String[] str=keyword.split(",");
		for(int i=0;i<str.length;i++){
			list.add(str[i]);
		}
		return list;
	}
	
}

```

#####  EcNewSimilarity  

自定义相似器 ,修改打分公式,直接影响搜索排名

```
import org.apache.lucene.index.FieldInvertState;
import org.apache.lucene.search.similarities.DefaultSimilarity;

/**
 * 扩展相似器   扩展自己的打分机制
 * @author bowen_bao
 *
 */
public class EcNewSimilarity extends DefaultSimilarity{	
	
	//词频
	@Override
	public float tf(float freq){//tf 开根号
		return 1.0f;
//		return freq;
	}
	
	//逆向文档频率：所有文档中出现的频率
	@Override
	public float idf(long docFreq,long numDocs){
		return 1.0f;
	}
	
	//长度因子  关键字占某文档包含所有词项的频率
	@Override
	public float lengthNorm(FieldInvertState state){
		return 1.0f;
	}
	
	
	//term 与   term 之间的距离因素
	@Override
	public float sloppyFreq(int distance){
		return 1.0f;
	}
	
	
	//每一个Document 中所有匹配的关键字与当前关键字的匹配比例因素影响
	//这个分值衡量了文档中含有多少term，文档中出现的越多，越全，将获得越高的分值。
	//demo:  查询lucene  和   apache  , 同时出现两个term 的肯定比只出现一个lucene 或者 apache 的分值高
	@Override
	public float coord(int overlap,int maxOverlap){
		return 1.0f;
	}
	
	
 
	/**
	 * 搜索权重因子  
	 * 这个标准化因子用于多个查询器中进行比较，它不影响文档的排名，它的主要作用在于多个查询器返回的结果进行比较，甚至是结果来自
	 * 多个索引时。这是搜索时的权重因子，当给查询器设置权重时就是通过这个因子进行影响的.
	 */
	 public float queryNorm(float sumOfSquaredWeights)//queryNorm 可以不用管，不影响排序结果
	    {
		 return 1.0f;
	    }	
	
}
```


##### PatternAnalyzer 

自定义分词器

```
import java.io.Reader;
import java.util.regex.Pattern;
import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.TokenStream;
import org.apache.lucene.analysis.core.LowerCaseFilter;
import org.apache.lucene.analysis.pattern.PatternTokenizer;

/**
 * 自定义分词器
 * @author bowen_bao
 *
 */
public class PatternAnalyzer extends  Analyzer{
	
	
	private Pattern pattern;
	private boolean toLowerCase;
	
	public PatternAnalyzer(String regex){
		this(regex,true);    //全部转小写
//		this(regex,false);   //不处理
	}
	public PatternAnalyzer(String regex,boolean toLowerCase){
		this.pattern=Pattern.compile(regex);
		this.toLowerCase=toLowerCase;
	}
	
	public PatternAnalyzer(Pattern pattern,boolean toLowerCase){
		this.pattern=pattern;
		this.toLowerCase=toLowerCase;
	}
	
	@SuppressWarnings("resource")
	@Override
	protected TokenStreamComponents createComponents(String arg0, Reader arg1) {
		PatternTokenizer tokenizer=new PatternTokenizer(arg1,pattern,-1);
		TokenStream result =toLowerCase?new LowerCaseFilter(tokenizer):tokenizer;
		return new TokenStreamComponents(tokenizer,result);
	}
	
}

```

#####  SortUtil


自定义排序规则

```
import org.apache.lucene.search.SortField;
import org.springframework.stereotype.Component;

/**
 * 根据业务或其排序规则
 * 
 * @author bowen_bao
 * 
 */
@Component("sortUtil")
public class SortUtil {


	/**
	 * @description 资讯的业务排序规则
	 */
	public SortField[] getEcnewSort() {

		// 资讯资料综合排序 sort
		SortField ecSort = new SortField("sortEc", SortField.Type.INT, true);

		// updatetime sort
		SortField publishtimeSort = new SortField("longpublishTime",
				SortField.Type.LONG, true);

		// SortField.FIELD_SCORE 文档得分
		SortField[] ecnewSort = new SortField[] { 
				SortField.FIELD_SCORE, ecSort,publishtimeSort };

		return ecnewSort;

	}

	public SortField[] getPnSort() {

		// 资讯资料综合排序 sort
		SortField pnSort = new SortField("sortPn", SortField.Type.INT, true);

		// updatetime sort
		SortField publishtimeSort = new SortField("longpublishTime",
				SortField.Type.LONG, true);

		// SortField.FIELD_SCORE 文档得分
		SortField[] sort = new SortField[] { SortField.FIELD_SCORE, pnSort,
				publishtimeSort };
		return sort;

	}

}

```

#####  QueryUtil 


自定义各类lucene Query  [这个类比较杂，无参考价值]

```
import java.io.IOException;
import java.io.StringReader;
import java.util.ArrayList;
import java.util.List;
import java.util.regex.Matcher;
import java.util.regex.Pattern;
import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.TokenStream;
import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
import org.apache.lucene.index.Term;
import org.apache.lucene.queryparser.classic.ParseException;
import org.apache.lucene.queryparser.classic.QueryParser;
import org.apache.lucene.search.BooleanClause;
import org.apache.lucene.search.BooleanClause.Occur;
import org.apache.lucene.search.BooleanQuery;
import org.apache.lucene.search.DisjunctionMaxQuery;
import org.apache.lucene.search.NumericRangeQuery;
import org.apache.lucene.search.PhraseQuery;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.TermQuery;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

@Component("queryUtil")
public class QueryUtil {
	
	private final Logger log = LoggerFactory.getLogger(this.getClass());
	
	@Autowired
	private SearchUtil searchUtil;
	
	//*****************************************************************业务Query
	
	/**
	 * 	单一词完全匹配，无需分词
	 * @param field   
	 * @param keyword
	 * @return
	 */
	public 	Query  getTermQuery(String field,String keyword){
		return	 new TermQuery(new Term(field,keyword.toLowerCase()));
	}	

	
	/**
	 * @describe 全命中匹配（无序）
	 * @param field
	 * @param keyword
	 * @param analyzer
	 * @return
	 */
	public  Query getFullHitQuery(String field,String keyword,Analyzer analyzer){
		try {
			List<String> wordList=getTokenList(keyword, analyzer);
			if(wordList.size()==0){
				return null;
			}
			BooleanQuery fullHitBQ=new BooleanQuery(true);//全部命中查询
			for(String word:wordList){
				fullHitBQ.add(new TermQuery(new Term(field,word)),BooleanClause.Occur.MUST);
			}
			return fullHitBQ;
		} catch (Exception e) {
			log.error("QueryUtil  getFullHitQuery error:",e);
		}
		return null;
	} 
	
	/**
	 * 部分命中匹配（无序）
	 */
	public  Query getPartHitQuery(String field,String keyword,Analyzer analyzer){
		try {
			List<String> wordList=getTokenList(keyword, analyzer);
			if(wordList.size()==0){
				return null;
			}
			
			wordList=singleFilter(wordList);
			if(wordList==null  ||  wordList.size()==0){
				return null;
			}
			
			BooleanQuery fullHitBQ=new BooleanQuery(true);
			for(String word:wordList){
				fullHitBQ.add(new TermQuery(new Term(field,word)),BooleanClause.Occur.SHOULD);
			}
			
			return fullHitBQ;
		} catch (Exception e) {
			log.error("QueryUtil  getPartHitQuery error:",e);
		}
		return null;
	} 
	
	
	
	/**
	 * 范围搜索
	 * @param field
	 * @param id
	 * @return
	 */

	public Query getNumericRangeQuery(String field,Integer id){
		Query queryid=NumericRangeQuery.newIntRange(field, id, id, true, true);
		return queryid;
	}
	
	/**
	 * 获取分词之后的数组
	 * @param text
	 * @param analyzer
	 * @return
	 */
	public List<String> getTokenList(String text ,Analyzer analyzer){
		if(null== text || text.trim().isEmpty()  || null==analyzer ){
			return new ArrayList<String>();
		}
		List<String> list=new ArrayList<String>();
		TokenStream ts=null;
		try {
			ts=analyzer.tokenStream(null, new StringReader(text));
			CharTermAttribute term=ts.addAttribute(CharTermAttribute.class);
			ts.reset();
			while(ts.incrementToken()){
				list.add(term.toString());
			}
			ts.end();
		} catch (Exception e) {
			log.error("EcNewIndexService  getTokenList error:",e);
		}finally{
			if(ts!=null){
				try {
					ts.close();
				} catch (IOException e) {
					log.error("EcNewIndexService  getTokenList error:",e);
				}
			}
		}
//		if(!list.contains(text)){
//			list.add(text);
//		}
		return list;
	}
	
	/**
	 * 判断是否是汉字
	 * @param c
	 * @return
	 */
	public boolean isChineseChar(char c){
		return c>=19968  &&  c<=40869;
	}
	
	/**
	 * 判断是否为中文词元
	 * @param keyword
	 * @param analyzer
	 * @return
	 */
	public boolean isSigleChinese(String keyword,Analyzer analyzer){
		List<String> wordList=getTokenList(keyword, analyzer);
		if(wordList==null || wordList.size()==0){
			return false;
		}
		if(wordList.size()==1){
			return true;
		}else{
			return false;
		}
		
	}
	
	
	
	
	
	//*********************************************************************非业务Query
	

	/**
	 * @describe  短语查询(全匹配)   待测试
	 * @author bowen_bao
	 * @date 2015年7月24日
	 * @param offset 默认为0
	 * @return
	 */
	public PhraseQuery getPhraseQuery(String field,String keyword,Analyzer analyzer,int offset){
		if(keyword==null || "".equals(keyword)){
			return null;
		}
		try {
			List<String> wordList=getTokenList(keyword, analyzer);
			if(wordList.size()==0){
				return null;
			}
			
			wordList=singleFilter(wordList);
			
			if(wordList==null  ||  wordList.size()==0){
				return null;
			}
			
			PhraseQuery phraseQuery=new PhraseQuery();
			phraseQuery.setSlop(offset);
			for(String word:wordList){
				phraseQuery.add(new Term(field,word));
			}
			return phraseQuery;
		} catch (Exception e) {
			log.error(e.getMessage());
		}
		return null;
	}
	
	
	
	public DisjunctionMaxQuery getPhraseQuerytest(String field,String keyword,Analyzer analyzer,int offset){
		if(keyword==null || "".equals(keyword)){
			return null;
		}
		try {
			List<String> wordList=getTokenList(keyword, analyzer);
			if(wordList.size()==0){
				return null;
			}
			DisjunctionMaxQuery maxQ=new DisjunctionMaxQuery(0.0f);
			BooleanQuery blQ=new BooleanQuery(true); 
			for(String word:wordList){
				PhraseQuery phraseQuery=new PhraseQuery();
				phraseQuery.setSlop(offset);
				phraseQuery.add(new Term(field,word));
				blQ.add(phraseQuery,Occur.MUST);
			}
			maxQ.add(blQ);
			return maxQ;
		} catch (Exception e) {
			log.error(e.getMessage());
		}
		return null;
	}

	
	
	
	
	
	
	
	/**
	 * 是否存在查询              存在- 加权值    
	 * @param field
	 * @param keyword
	 * @param analyzer
	 * @param allWeight
	 * @param partWeight
	 * @return
	 */
	public Query isExistQuery(String field,String keyword,Analyzer analyzer,float weight){
		BooleanQuery blQ=new BooleanQuery(true);
		boolean isSigleChinese=isSigleChinese(keyword, analyzer);
		if(isSigleChinese){
			//全匹配Query
			Query allQ=getTermQuery(field,keyword);
			allQ.setBoost(weight);
			blQ.add(allQ,Occur.SHOULD);
		}else{
			List<String> wordList=getTokenList(keyword, analyzer);
			if(wordList==null  ||  wordList.size()==0){
				return null;
			}
			//分词部分匹配Query
			Query partQ=getPartHitQuery(field,keyword,analyzer);
			partQ.setBoost(weight);
			blQ.add(partQ,Occur.SHOULD);
		}
		
		return blQ;
	}
	
	
	
	
	/**
	 * 	单一词完全匹配，无需分词
	 * @param field   
	 * @param keyword
	 * @return
	 */
	public 	Query  getSingleQuerybak(String field,String keyword,Analyzer analyzer){
		try {
			List<String> wordList=getTokenList(keyword, analyzer);
			if(wordList.size()==0){
				return null;
			}else if(wordList.size()==1){
				BooleanQuery fullHitBQ=new BooleanQuery(true);
				for(String word:wordList){
					fullHitBQ.add(new TermQuery(new Term(field,word)),Occur.MUST);
				}
				return fullHitBQ;
			}else{
				return null;
			}
		} catch (Exception e) {
			log.error("QueryUtil  getPartHitQuery error:",e);
		}
		return null;
	}
	
	
	public List<String> singleFilter(List<String> wordList){
		if(wordList==null || wordList.size()==0){
			return null;
		}
		if(wordList.size()>1){
			List<String> list=new ArrayList<String>();
			
			if(wordList.size()==2){
				if(wordList.get(0).toLowerCase().endsWith(wordList.get(1).toLowerCase())){
					list.add(wordList.get(0));
					return list;
				}
			}
			
			for(String s:wordList){
				 Pattern intP =Pattern.compile("[0-9]");
				 Pattern strP =Pattern.compile("[a-zA-Z]");
				 if(!intP.matcher(s).matches()&& !strP.matcher(s).matches()){
						String regEx="[\\u4e00-\\u9fa5]";
						Pattern p=Pattern.compile(regEx);
						Matcher m=p.matcher(s);
						int nCount=0;
						while(m.find()){
							 for(int i=0;i<=m.groupCount();i++){
								 nCount++;
							 }
						}
						if(nCount!=1){
							list.add(s);
						}
				 } 
			}
			return list;
		}
		
		return wordList;
	}
	
	
	//===============================================v2 新增
	public Query fieldListKeywordTermQuery(String field,String keyword,Analyzer analyzer){
			BooleanQuery blQ=new BooleanQuery(true);
			List<String> wordList=getTokenList(keyword, analyzer);
			if(wordList==null  ||  wordList.size()==0){
				return null;
			}
			for(String k:wordList){
				Query q=getTermQuery(field, k);
				blQ.add(q,Occur.SHOULD);
			}
		return blQ;
	}
	
	
	public Query getKeywordPharseQuery(String field,String keyword,Analyzer analyzer,int offset)throws ParseException {
		QueryParser parser=new QueryParser(field, analyzer);
		Query q= parser.createPhraseQuery(field, keyword, offset);
		return q;
	}
	
	public Query getKeywordHalfMatchQuery(String field,String keyword,Analyzer analyzer,boolean isHalf)throws ParseException {
		if(keyword==null || "".equals(keyword)){
			return null;
		}
		try {
			BooleanQuery blQ=new BooleanQuery(true);
			List<String> wordList=getTokenList(keyword, analyzer);
			wordList=singleFilter(wordList);
			if(wordList.size()==0){
				return null;
			}
			for(String word:wordList){
				if(isHalf){
					if(word.length()*2>=keyword.length()){
						Query q=getTermQuery(field, word);
						blQ.add(q, Occur.SHOULD);
					}
				}else{
					if(word.length()*2<keyword.length()){
						Query q=getTermQuery(field, word);
						blQ.add(q, Occur.SHOULD);
					}
				}
			}
			return blQ;
		} catch (Exception e) {
			log.error(e.getMessage());
		}
		return null; 
	}
	
	//只能做坡度为0的短语查询
	public Query getQuestionTitleQuery1(String field,String keyword,Analyzer analyzer)throws ParseException {
		QueryParser parser=new QueryParser(field, analyzer);
		Query q= parser.createPhraseQuery(field, keyword);
		return q;
	}
	
	public Query getQuestionTitleQuery(String field,String keyword,Analyzer analyzer)throws ParseException {
		QueryParser parser=new QueryParser(field, analyzer);
		Query q= parser.parse(keyword);
		return q;
	}
	
	
	
}

```


#####  IkHightLight 

高亮处理

```
import java.io.IOException;
import java.io.StringReader;
import java.util.ArrayList;
import java.util.List;
import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.TokenStream;
import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
import org.apache.lucene.index.Term;
import org.apache.lucene.search.BooleanClause;
import org.apache.lucene.search.BooleanQuery;
import org.apache.lucene.search.PhraseQuery;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.highlight.Highlighter;
import org.apache.lucene.search.highlight.NullFragmenter;
import org.apache.lucene.search.highlight.QueryScorer;
import org.apache.lucene.search.highlight.SimpleHTMLFormatter;
import org.springframework.stereotype.Component;
import org.wltea.analyzer.lucene.IKAnalyzer;
import com.sekorm.searchengine.common.constant.SearchConstant;
import com.sekorm.searchengine.searchutil.PatternAnalyzer;
import com.sekorm.searchengine.vo.SearchEcObjVO;


@Component("ikHightLight")
public class IkHightLight {
	// 搜索高亮标签
	public static final String HIGHLIGHT_BEGIN =   SearchConstant.HIGHLIGHT_BEGIN; // 高亮开始标记符    
	public static final String HIGHLIGHT_END = SearchConstant.HIGHLIGHT_END; // 高亮结束标记符

	public static void main(String[] args) {
//		String title = "PCap01AX";
//		String keyword = "PCap01A";
//
//		// ik分词，分出来标红
//		IKAnalyzer ikAnalyzer = new IKAnalyzer();
//		List<String> ikTokenList = getTokenList(keyword, ikAnalyzer);
//		System.out.println("keyword=" + keyword);
//		System.out.println("===ik分词===");
//		for (String token : ikTokenList) {
//			System.out.println(token);
//		}
//
//		// 构造高亮查询
//		BooleanQuery highLightQuery = new BooleanQuery();
//		PatternAnalyzer patternAnalyzer = new PatternAnalyzer(""); // 单字符分词
//		for (String token : ikTokenList) {
//			Query phraseQuery = getPhraseQuery("title", token, patternAnalyzer);
//			highLightQuery.add(phraseQuery, BooleanClause.Occur.SHOULD);
//		}
//
//		// 高亮标题
//		String highLightTitle = highLight(title, highLightQuery,
//				patternAnalyzer);
//		System.out.println("title=" + title);
//		System.out.println("highLightTitle=" + highLightTitle);
		
//		List<SearchEcObjVO> list=new ArrayList<SearchEcObjVO>();
//		SearchEcObjVO vo=new SearchEcObjVO();
//		 vo.setTitle("PCap01AX"); list.add(vo);
//		 sekormhigh(list,"PCap01");
//		 
//		 for(SearchEcObjVO v:list){
//			 System.out.println(v.getTitle());
//		 }
	}
	
	
	public   void sekormhigh(List<SearchEcObjVO> list,String keyword){

		// ik分词，分出来标红
		IKAnalyzer ikAnalyzer = new IKAnalyzer();
		List<String> ikTokenList = getTokenList(keyword, ikAnalyzer);
		for (String token : ikTokenList) {
			System.out.println(token);
		}

		// 构造高亮查询
		BooleanQuery highLightQuery = new BooleanQuery();
		PatternAnalyzer patternAnalyzer = new PatternAnalyzer(""); // 单字符分词
		for (String token : ikTokenList) {
			Query phraseQuery = getPhraseQuery("title", token, patternAnalyzer);
			highLightQuery.add(phraseQuery, BooleanClause.Occur.SHOULD);
		}

		// 高亮标题
		for(SearchEcObjVO ecnew:list){//只高亮title  summery
			ecnew.setTitle(highLight(ecnew.getTitle(),highLightQuery,patternAnalyzer));
			ecnew.setSummary(highLight(ecnew.getSummary(),highLightQuery,patternAnalyzer));
		}
		 
	}

	public static String highLight(String title, Query query, Analyzer analyzer) {
		// 高亮器
		SimpleHTMLFormatter simpleHTMLFormatter = new SimpleHTMLFormatter(
				HIGHLIGHT_BEGIN, HIGHLIGHT_END);
		Highlighter highlighter = new Highlighter(simpleHTMLFormatter,
				new QueryScorer(query));
		highlighter.setTextFragmenter(new NullFragmenter());

		// 高亮标题
		String hTitle = highLight(title, highlighter, analyzer);
		return hTitle;
	}

	/**
	 * 高亮文本
	 * 
	 * @param text
	 * @param highlighter
	 * @param analyzer
	 * @return 失败：null
	 */
	public static String highLight(String text, Highlighter highlighter,
			Analyzer analyzer) {
		if (text == null || text.length() == 0) {
			return text;
		}

		try {
			String hlText = highlighter.getBestFragment(analyzer, null, text);
			if (hlText != null) {
				// 合并连续命中区域
				hlText = hlText.replace(HIGHLIGHT_END + HIGHLIGHT_BEGIN, ""); // 中文文本存在此情况
				hlText = hlText.replace(HIGHLIGHT_END + " " + HIGHLIGHT_BEGIN,
						" "); // 英文文本存在此情况
				return hlText;
			} else {
				return text;
			}
		} catch (Exception e) {
			e.printStackTrace();
		}

		return null;
	}

	/**
	 * 返回分词后的词列表
	 * 
	 * @param text
	 * @param analyzer
	 * @return 失败：返回空List
	 */
	public static List<String> getTokenList(String text, Analyzer analyzer) {
		if (null == text || text.trim().isEmpty() || null == analyzer) {
			return new ArrayList<String>();
		}

		List<String> list = new ArrayList<String>();

		TokenStream ts = null;// 获取Lucene的TokenStream对象
		try {
			ts = analyzer.tokenStream(null, new StringReader(text));
			CharTermAttribute term = ts.addAttribute(CharTermAttribute.class);// 获取词元文本属性
			ts.reset(); // 重置TokenStream（重置StringReader）
			while (ts.incrementToken()) {// 迭代获取分词结果
				list.add(term.toString());
			}
			ts.end(); // Perform end-of-stream operations, e.g. set the final
						// offset.
		} catch (IOException e) {
			e.printStackTrace();
		} finally {
			if (ts != null) {// 释放TokenStream的所有资源
				try {
					ts.close();
				} catch (IOException e) {
					e.printStackTrace();
				}
			}
		}

		return list;
	}

	/**
	 * 构造短语查询
	 * 
	 * @param field
	 * @param keyword
	 * @param analyzer
	 * @return 失败：null
	 */
	public static PhraseQuery getPhraseQuery(String field, String keyword,
			Analyzer analyzer) {
		if (keyword == null || keyword.length() == 0) {
			return null;
		}

		try {
			// 得到分词词条
			List<String> wordList = getTokenList(keyword, analyzer);
			if (wordList.size() == 0) {
				return null;
			}
			// 构造短语查询
			PhraseQuery phraseQuery = new PhraseQuery();
			for (String word : wordList) {
				phraseQuery.add(new Term(field, word));
			}
			return phraseQuery;
		} catch (Exception e) {
			e.printStackTrace();
		}
		return null;
	}	
	
}

```



